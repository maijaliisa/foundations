{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "## I don't know what you've installed or how you've installed it, so let's talk before you run any of this.\n",
    "\n",
    "**OS X folks** can run the following:\n",
    "\n",
    "* `brew install geos`\n",
    "* `brew install gdal`\n",
    "* `brew install spatialindex`\n",
    "* `pip3 install pillow`\n",
    "* `pip3 install pysal`\n",
    "* `pip3 install geopandas`\n",
    "* `pip3 install https://github.com/matplotlib/basemap/archive/v1.0.7rel.tar.gz`\n",
    "* `pip3 install rtree`\n",
    "\n",
    "For **Windows without Anaconda**, [use this guide](http://geoffboeing.com/2014/09/using-geopandas-windows/) to install through `pip` directly from `whl` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geopandas Usage\n",
    "\n",
    "## Importing\n",
    "\n",
    "You'll be importing\n",
    "\n",
    "* pandas because you love it\n",
    "* geopandas for geographic stuff\n",
    "* `Point` from shapely to help convert CSV files into something geopandas can understand\n",
    "\n",
    "and `%matplotlib inline` for viewing maps, of course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a shapefile\n",
    "\n",
    "Let's open up the Community Districts data. **What kind of file is it?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "no such file or directory: 'Community Districts/districts.shp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bde96a75dbe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdistricts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Community Districts/districts.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m     20\u001b[0m     \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bbox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfiona\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/fiona/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such archive file: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no such file or directory: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         c = Collection(path, mode, driver=driver, encoding=encoding,\n\u001b[1;32m    164\u001b[0m                        \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvsi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: no such file or directory: 'Community Districts/districts.shp'"
     ]
    }
   ],
   "source": [
    "districts = gpd.read_file(\"Community Districts/districts.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the GeoDataFrame\n",
    "\n",
    "A GeoDataFrame is *just like a dataframe*, it just... has geographic stuff in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts[districts.boro_cd > 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing a shapefile\n",
    "\n",
    "You can just use `.plot()` to visualize a GeoDataFrame, it's nice and easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the CRS (Coordinate Reference System)\n",
    "\n",
    "### WAY ONE: Just changing the Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go into the crs to convert it...\n",
    "# ignore the datum and spheroid,\n",
    "# just change the PROJECTION to MERCATOR\n",
    "districts.to_crs({'proj': 'merc'}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give it the SECRET CODE from the PETROLEUM GROUP\n",
    "# (which you can try to find by googling)\n",
    "# (or hopefully you have a list because they're\n",
    "# all very confusingly/similarly named)\n",
    "districts.to_crs(epsg=3857).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening a CSV of points\n",
    "\n",
    "geopandas doesn't understand a CSV file of lat/lon points, so you need to convert each line into shapely geometry, then feed that into a new geo dataframe.\n",
    "\n",
    "Once you do that, you need to set the `crs` to `{'init': 'epsg:4326'}` so it knows what kind of datum/sphereoid/projection you're measuring from.\n",
    "\n",
    "**Let's try opening the earthquakes CSV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"earthquakes_1.0_day.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_point(row):\n",
    "    return Point(row.longitude, row.latitude)\n",
    "\n",
    "# Go through every row, and make a point out of its lat and lon\n",
    "points = df.apply(make_point, axis=1)\n",
    "\n",
    "# Make a new GeoDataFrame\n",
    "# using the data from our old df\n",
    "# but also adding in the geometry we just made\n",
    "earthquakes = gpd.GeoDataFrame(df, geometry=points)\n",
    "\n",
    "# It doesn't come with a CRS because it's a CSV, so let's\n",
    "# say \"hey, let's use the standard shape of the earth etc\"\n",
    "earthquakes.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# Let's look at the first few\n",
    "earthquakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV\n",
    "df = pd.read_csv(\"earthquakes_1.0_day.csv\")\n",
    "\n",
    "points = df.apply(lambda row: Point(row.longitude, row.latitude), axis=1)\n",
    "earthquakes = gpd.GeoDataFrame(df, geometry=points)\n",
    "earthquakes.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# If you want to know how this all works, look above\n",
    "earthquakes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.plot(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the built-in map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "ax = world.plot(figsize=(20,5))\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Styling your visuals\n",
    "\n",
    "## Setting size, line and shape colors, widths, axes\n",
    "\n",
    "* `linewidth`\n",
    "* `color`\n",
    "* `edgecolor`\n",
    "* `ax.axis`\n",
    "\n",
    "Let's plot the community districts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.plot(figsize=(20,5), linewidth=0.25, edgecolor='white', color='lightgrey')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the world!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = districts.to_crs(epsg=3857).plot(figsize=(20,5), linewidth=0.25, edgecolor='white', color='pink')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the projection\n",
    "\n",
    "You can use `to_crs` to convert to different projections. In typical pandas fashion, you can do it a lot of ways, but the easiest is to send a `epsg=` and feed it the correct EPSG code.\n",
    "\n",
    "You'll also probably want to do an `ax.axis('off')` to turn off the splines and axes!\n",
    "\n",
    "What are the EPSG codes for some common projections?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.plot(figsize=(20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Styling markers\n",
    "\n",
    "* markersize\n",
    "* color\n",
    "* alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the earthquakes:\n",
    "# BIGGER CIRCLES\n",
    "# all one color\n",
    "# make them a little transparent\n",
    "# NO AXES OR BORDERS AROUND THE MAP!!!!!!!\n",
    "\n",
    "ax = earthquakes.plot(figsize=(20,5), markersize=10, color='pink', alpha=0.5)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the earthquakes:\n",
    "# BIGGER CIRCLES\n",
    "# all one color\n",
    "# make them a little transparent\n",
    "# NO AXES OR BORDERS AROUND THE MAP!!!!!!!\n",
    "\n",
    "# Save the first layer as ax\n",
    "ax = world.plot(color='lightgrey', linewidth=0.5, edgecolor='white', figsize=(15,5))\n",
    "# Pass ax=ax to the second layer\n",
    "earthquakes.plot(markersize=10, color='pink', alpha=0.5, ax=ax)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colormaps/ramps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto colormap\n",
    "\n",
    "Giving your `plot` a `column` and a `cmap` will colorize your values. You can try `plasma` as your color map, or check out [more here](https://matplotlib.org/examples/color/colormaps_reference.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the earthquakes:\n",
    "# BIGGER CIRCLES\n",
    "# all one color\n",
    "# make them a little transparent\n",
    "# NO AXES OR BORDERS AROUND THE MAP!!!!!!!\n",
    "\n",
    "# Save the first layer as ax\n",
    "ax = world.plot(color='lightgrey', linewidth=0.5, edgecolor='white', figsize=(15,5))\n",
    "# Pass ax=ax to the second layer\n",
    "earthquakes.plot(markersize=10, alpha=0.5, ax=ax, column='mag')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the earthquakes:\n",
    "# BIGGER CIRCLES\n",
    "# all one color\n",
    "# make them a little transparent\n",
    "# NO AXES OR BORDERS AROUND THE MAP!!!!!!!\n",
    "\n",
    "# Save the first layer as ax\n",
    "ax = world.plot(color='lightgrey', linewidth=0.5, edgecolor='white', figsize=(15,5))\n",
    "# Pass ax=ax to the second layer\n",
    "earthquakes.plot(markersize=10, alpha=0.5, ax=ax, column='mag', cmap='plasma')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto colormap again\n",
    "\n",
    "We can also try with the world. What's the `gdp_md_est` column looking like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.plot(column='gdp_md_est', cmap='inferno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.plot(column='pop_est', cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting multiple layers of data\n",
    "\n",
    "Let's try plotting the earthquakes on top of the world. **Save your first plot as `ax` and send it to the next one as `ax=ax`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the projection by `proj` with named projections\n",
    "\n",
    "Instead of using an EPSG code, you can also set the projection with `to_crs` by  `.to_crs({'proj': 'merc'})` or something similar.\n",
    "\n",
    "I don't recommend this method, but it is a little friendlier than EPSG codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the world with the default projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.plot()\n",
    "ax.set_title(\"Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the world with Mercator (merc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.to_crs({'proj': 'merc'}).plot()\n",
    "ax.set_title(\"Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the world with [Transverse Mercator](https://en.wikipedia.org/wiki/Transverse_Mercator_projection) (tmerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.to_crs({'proj': 'tmerc'}).plot()\n",
    "ax.set_title(\"Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the world with Albers Equal Area (aea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = world.to_crs({'proj': 'aea'}).plot()\n",
    "ax.set_title(\"Default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial join\n",
    "\n",
    "# Dataset 1: States\n",
    "\n",
    "Let's import the states and clean them up a little bit. we need to clean the data up a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the shapefile from cb_2016_us_state_500k as \"states\"\n",
    "states = gpd.read_file(\"cb_2016_us_state_500k/cb_2016_us_state_500k.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of Guam, Mariana Islands and Virgin Islands\n",
    "states = states[states.STATEFP.astype(int) < 60]\n",
    "# Get rid of Hawaii and Alaska\n",
    "states = states[~states.NAME.isin(['Hawaii', 'Alaska'])]\n",
    "states.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Waffle House\n",
    "\n",
    "Read in `wafflehouses.csv`, and convert it to a GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV\n",
    "df = pd.read_csv(\"wafflehouses.csv\")\n",
    "\n",
    "points = df.apply(lambda row: Point(row.long, row.lat), axis=1)\n",
    "wafflehouses = gpd.GeoDataFrame(df, geometry=points)\n",
    "wafflehouses.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# If you want to know how this all works, look above\n",
    "wafflehouses.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the locations, coloring based on the 'score' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.plot()\n",
    "wafflehouses.plot(column='score', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The actual spatial join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the CRS of the states the same as the CRS of the Waffle House locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafflehouses.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If not, we'll force them to match using `.to_crs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS to match\n",
    "converted_states = states.to_crs(wafflehouses.crs)\n",
    "converted_states.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_states.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafflehouses.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now we can join\n",
    "\n",
    "Open up Terminal and run\n",
    "\n",
    "* pip install rtree\n",
    "* brew install spatialindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafflehouses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_states.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_states.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafflehouses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://geopandas.org/mergingdata.html\n",
    "wafflehouses_with_state_data = gpd.sjoin(wafflehouses, converted_states, how='left', op='within')\n",
    "wafflehouses_with_state_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafflehouses_with_state_data['NAME'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing things with spatially joined data\n",
    "\n",
    "* What column do we use for color?\n",
    "* Add a legend with `legend=True`\n",
    "* Something is going to go wrong, though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need dropna because some wafflehouses are missing states\n",
    "wafflehouses_with_state_data.dropna().plot(column='NAME', markersize=10, figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we reverse the spatial join and make it 'contains'?\n",
    "\n",
    "How is this different than what we did before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://geopandas.org/mergingdata.html\n",
    "states_with_wafflehouse_data = gpd.sjoin(converted_states, wafflehouses, how='left', op='contains')\n",
    "states_with_wafflehouse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_with_wafflehouse_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = states_with_wafflehouse_data[['NAME', 'geometry', 'score']]\n",
    "select_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating with `.dissolve` (the geographic version of 'groupby')\n",
    "\n",
    "http://geopandas.org/aggregation_with_dissolve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In theory we'd run the following line\n",
    "\n",
    "But it doesn't work because we have too much data, and `.dissolve` isn't smart enough to deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can't do this, I think because there are too many wafflehouses\n",
    "#wafflehouse_counts = states_with_wafflehouse_data.dissolve(by='NAME', aggfunc='count')\n",
    "#wafflehouse_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But we can try it out with the first 5/20/50 of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "select_columns.head(5).dissolve(by='NAME', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "select_columns.head(20).dissolve(by='NAME', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "select_columns.head(50).dissolve(by='NAME', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "select_columns.head(200).dissolve(by='NAME', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial joins for LARGE data sets (NOT using dissolve)\n",
    "\n",
    "Instead of using `.dissolve`, we need to use `.contains` to say \"find me all of the waffle houses inside of this one specific state\". I don't know why this works better, but it does. We'll use `.sum()` to count the number inside, but you could also do something like `['score'].mean()` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's try it with one state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[0].geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False = 0\n",
    "# True = 1\n",
    "# Count the number of states where the name contains \"New\"\n",
    "states.NAME.str.contains(\"New\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give me the first state!\n",
    "state = states.loc[0]\n",
    "# Look at the wafflehouses...\n",
    "# are they inside of the state's geometry?\n",
    "wafflehouses.within(state.geometry).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So for our first state, there were 147 inside of there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's try it with every state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use .contains\n",
    "# counts the true ones\n",
    "states['wafflehouse_count'] = states.apply(lambda state: wafflehouses.within(state.geometry).sum(), axis=1)\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(column='wafflehouse_count', scheme='quantiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(column='wafflehouse_count', scheme='equal_interval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.plot(column='wafflehouse_count', scheme='fisher_jenks', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial joins for SMALLER data sets (YES using dissolve)\n",
    "\n",
    "If our dataset isn't that big, though, we're fine to use `.dissolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each one is a country\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how every country has a continent? We can `.dissolve` to group them together based on continent. It's like groupby, really!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we'll dissolve them so it's only continents\n",
    "continents = world.dissolve(by='continent', aggfunc='sum')\n",
    "continents.head()\n",
    "continents.plot(column='pop_est')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving the results\n",
    "\n",
    "You want to look at this stuff in Leaflet, right? For that we'll need to save. Geopandas supports practically _every_ file format you could ever want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wafflehouses_with_state_data.to_file(\"wafflehouses.json\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
